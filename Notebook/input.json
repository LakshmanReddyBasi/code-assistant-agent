{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca7dd20",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# 🧠 Code Assistant (Debug, Explain, Refactor)\\n\",\n",
    "    \"\\n\",\n",
    "    \"A complete LangChain-based system that explains, debugs, and refactors code using **Groq's Llama 3.3 70B**, local vector memory, and a tool-using agent.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## ✅ Assignment Requirements Met\\n\",\n",
    "    \"1. **Use LLMs** – Groq + `llama-3.3-70b-versatile` (active model)\\n\",\n",
    "    \"2. **Prompt Templates** – Standardized JSON output\\n\",\n",
    "    \"3. **Build Chains** – LangChain pipelines\\n\",\n",
    "    \"4. **Load Documents** – `.py`, `.js`, `.java` support\\n\",\n",
    "    \"5. **Split Large Code** – Recursive chunking\\n\",\n",
    "    \"6. **Embeddings & Vectorstores** – FAISS + Hugging Face\\n\",\n",
    "    \"7. **RetrievalQA** – Ask natural-language questions\\n\",\n",
    "    \"8. **Tools & Agents** – Read, lint, run, refactor\\n\",\n",
    "    \"9. **Parse Outputs** – `{summary, steps, issues_found, refactored_code}`\\n\",\n",
    "    \"\\n\",\n",
    "    \"## 🔁 Workflow Diagram\\n\",\n",
    "    \"- User uploads code file\\n\",\n",
    "    \"- System loads & splits if large\\n\",\n",
    "    \"- **Agent uses tools**: read → lint → run tests\\n\",\n",
    "    \"- LLM generates structured analysis\\n\",\n",
    "    \"- Result saved to `output.json` + **stored in vector DB**\\n\",\n",
    "    \"- Enables **RetrievalQA**: *“What does this function do?”*\\n\",\n",
    "    \"\\n\",\n",
    "    \"> 💡 **Model Status**: `llama-3.3-70b-versatile` is the **recommended replacement** for `llama3-70b-8192` (deprecated Aug 30, 2025 — see [Groq Docs](https://console.groq.com/docs/deprecations)).\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Install dependencies (run once)\\n\",\n",
    "    \"!pip install -q langchain-groq langchain-huggingface langchain-community faiss-cpu sentence-transformers python-dotenv pylint\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import everything\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import tempfile\\n\",\n",
    "    \"import subprocess\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"from datetime import datetime\\n\",\n",
    "    \"\\n\",\n",
    "    \"from dotenv import load_dotenv\\n\",\n",
    "    \"from langchain_groq import ChatGroq\\n\",\n",
    "    \"from langchain_huggingface import HuggingFaceEmbeddings\\n\",\n",
    "    \"from langchain_community.vectorstores import FAISS\\n\",\n",
    "    \"from langchain_core.prompts import ChatPromptTemplate\\n\",\n",
    "    \"from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\\n\",\n",
    "    \"from langchain.agents import create_tool_calling_agent, AgentExecutor\\n\",\n",
    "    \"from langchain.tools import tool\\n\",\n",
    "    \"from langchain_text_splitters import RecursiveCharacterTextSplitter\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load API key\\n\",\n",
    "    \"os.environ[\\\"GROQ_API_KEY\\\"] = \\\"your_groq_api_key_here\\\"  # 👈 REPLACE THIS\\n\",\n",
    "    \"MODEL = \\\"llama-3.3-70b-versatile\\\"  # ✅ Active per Groq deprecation log\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"# TOOLS\\n\",\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"@tool\\n\",\n",
    "    \"def read_code_file(filename: str) -> str:\\n\",\n",
    "    \"    \\\"\\\"\\\"Read code file.\\\"\\\"\\\"\\n\",\n",
    "    \"    return Path(filename).read_text(encoding='utf-8')\\n\",\n",
    "    \"\\n\",\n",
    "    \"@tool\\n\",\n",
    "    \"def analyze_with_linter(code: str, language: str = \\\"python\\\") -> str:\\n\",\n",
    "    \"    \\\"\\\"\\\"Lint Python code.\\\"\\\"\\\"\\n\",\n",
    "    \"    if language != \\\"python\\\": return \\\"Linter only for Python.\\\"\\n\",\n",
    "    \"    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\\n\",\n",
    "    \"        f.write(code)\\n\",\n",
    "    \"        path = f.name\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        result = subprocess.run([\\\"python\\\", \\\"-m\\\", \\\"pylint\\\", \\\"--reports=no\\\", path],\\n\",\n",
    "    \"                              capture_output=True, text=True, timeout=10)\\n\",\n",
    "    \"        return result.stdout.strip() or \\\"No lint issues.\\\"\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        return f\\\"Linter error: {e}\\\"\\n\",\n",
    "    \"    finally:\\n\",\n",
    "    \"        Path(path).unlink(missing_ok=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"@tool\\n\",\n",
    "    \"def execute_code_safely(code: str, language: str = \\\"python\\\") -> str:\\n\",\n",
    "    \"    \\\"\\\"\\\"Safely execute Python code.\\\"\\\"\\\"\\n\",\n",
    "    \"    if language != \\\"python\\\": return \\\"Execution only for Python.\\\"\\n\",\n",
    "    \"    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\\n\",\n",
    "    \"        f.write(code)\\n\",\n",
    "    \"        path = f.name\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        result = subprocess.run([\\\"python\\\", path], capture_output=True, text=True, timeout=5)\\n\",\n",
    "    \"        return result.stdout.strip() if result.returncode == 0 else f\\\"Error: {result.stderr.strip()}\\\"\\n\",\n",
    "    \"    except subprocess.TimeoutExpired:\\n\",\n",
    "    \"        return \\\"Error: Code timed out.\\\"\\n\",\n",
    "    \"    finally:\\n\",\n",
    "    \"        Path(path).unlink(missing_ok=True)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"# VECTOR STORE\\n\",\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"class VectorStoreManager:\\n\",\n",
    "    \"    def __init__(self, index_path=\\\"code_index\\\"):\\n\",\n",
    "    \"        self.index_path = index_path\\n\",\n",
    "    \"        self.embeddings = HuggingFaceEmbeddings(model_name=\\\"sentence-transformers/all-MiniLM-L6-v2\\\")\\n\",\n",
    "    \"        self.vectorstore = self._load_or_create()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def _load_or_create(self):\\n\",\n",
    "    \"        if Path(self.index_path).exists():\\n\",\n",
    "    \"            return FAISS.load_local(self.index_path, self.embeddings, allow_dangerous_deserialization=True)\\n\",\n",
    "    \"        empty = FAISS.from_texts([\\\"\\\"], self.embeddings)\\n\",\n",
    "    \"        empty.save_local(self.index_path)\\n\",\n",
    "    \"        return empty\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def add_experience(self, task, original, refactored, issues, validation):\\n\",\n",
    "    \"        text = f\\\"[Task: {task}]\\\\n[Original]\\\\n{original}\\\\n[Refactored]\\\\n{refactored}\\\\n[Issues]\\\\n{'\\\\n'.join(issues)}\\\\n[Validation]\\\\n{validation}\\\"\\n\",\n",
    "    \"        self.vectorstore.add_texts([text])\\n\",\n",
    "    \"        self.vectorstore.save_local(self.index_path)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def retrieve(self, query, k=2):\\n\",\n",
    "    \"        results = self.vectorstore.similarity_search(query, k=k)\\n\",\n",
    "    \"        return \\\"\\\\n\\\\n\\\".join(r.page_content for r in results)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"# AGENT & CHAINS\\n\",\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"def create_code_agent():\\n\",\n",
    "    \"    llm = ChatGroq(model=MODEL, temperature=0)\\n\",\n",
    "    \"    tools = [read_code_file, analyze_with_linter, execute_code_safely]\\n\",\n",
    "    \"    prompt = ChatPromptTemplate.from_messages([\\n\",\n",
    "    \"        (\\\"system\\\", \\\"You are a senior code assistant. Use tools to analyze code.\\\"),\\n\",\n",
    "    \"        (\\\"human\\\", \\\"{input}\\\"),\\n\",\n",
    "    \"        (\\\"placeholder\\\", \\\"{agent_scratchpad}\\\")\\n\",\n",
    "    \"    ])\\n\",\n",
    "    \"    agent = create_tool_calling_agent(llm, tools, prompt)\\n\",\n",
    "    \"    return AgentExecutor(agent=agent, tools=tools, verbose=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"def create_json_formatter():\\n\",\n",
    "    \"    llm = ChatGroq(model=MODEL, temperature=0)\\n\",\n",
    "    \"    prompt = ChatPromptTemplate.from_template(\\\"\\\"\\\"\\n\",\n",
    "    \"Convert to JSON with keys: summary, steps, issues_found, refactored_code.\\n\",\n",
    "    \"Analysis: {analysis}\\n\",\n",
    "    \"Respond ONLY with valid JSON.\\n\",\n",
    "    \"\\\"\\\"\\\")\\n\",\n",
    "    \"    return prompt | llm | JsonOutputParser()\\n\",\n",
    "    \"\\n\",\n",
    "    \"def create_qa_chain():\\n\",\n",
    "    \"    llm = ChatGroq(model=MODEL, temperature=0)\\n\",\n",
    "    \"    prompt = ChatPromptTemplate.from_template(\\\"Answer based on context.\\\\nContext:\\\\n{context}\\\\nQuestion: {question}\\\\nAnswer:\\\")\\n\",\n",
    "    \"    return prompt | llm | StrOutputParser()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"# CREATE SAMPLE FILE\\n\",\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"Path(\\\"sample_code\\\").mkdir(exist_ok=True)\\n\",\n",
    "    \"buggy_code = '''\\n\",\n",
    "    \"def find_max(numbers):\\n\",\n",
    "    \"    max_val = 0\\n\",\n",
    "    \"    for num in numbers:\\n\",\n",
    "    \"        if num > max_val:\\n\",\n",
    "    \"            max_val = num\\n\",\n",
    "    \"    return max_val\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(find_max([-5, -2, -10]))\\n\",\n",
    "    \"'''\\n\",\n",
    "    \"Path(\\\"sample_code/buggy.py\\\").write_text(buggy_code)\\n\",\n",
    "    \"print(\\\"✅ Created sample_code/buggy.py\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"# MAIN: CODE ASSISTANT\\n\",\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"def code_assistant(file_path, task=\\\"explain\\\"):\\n\",\n",
    "    \"    code = Path(file_path).read_text(encoding='utf-8')\\n\",\n",
    "    \"    lang = {\\\"py\\\": \\\"python\\\", \\\"js\\\": \\\"javascript\\\", \\\"java\\\": \\\"java\\\"}.get(Path(file_path).suffix[1:], \\\"python\\\")\\n\",\n",
    "    \"    snippet = code[:1200]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    agent = create_code_agent()\\n\",\n",
    "    \"    agent_out = agent.invoke({\\\"input\\\": f\\\"{task.capitalize()} this {lang} code:\\\\n\\\\n{snippet}\\\"})\\n\",\n",
    "    \"\\n\",\n",
    "    \"    formatter = create_json_formatter()\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        result = formatter.invoke({\\\"analysis\\\": agent_out[\\\"output\\\"]})\\n\",\n",
    "    \"    except:\\n\",\n",
    "    \"        result = {\\n\",\n",
    "    \"            \\\"summary\\\": \\\"Agent completed analysis\\\",\\n\",\n",
    "    \"            \\\"steps\\\": [\\\"Used linting and execution tools\\\"],\\n\",\n",
    "    \"            \\\"issues_found\\\": [\\\"Parsing fallback\\\"],\\n\",\n",
    "    \"            \\\"refactored_code\\\": snippet\\n\",\n",
    "    \"        }\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Validate\\n\",\n",
    "    \"    validation = \\\"Not validated\\\"\\n\",\n",
    "    \"    if task in [\\\"debug\\\", \\\"refactor\\\"]:\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            validation = execute_code_safely(result.get(\\\"refactored_code\\\", snippet), lang)\\n\",\n",
    "    \"        except:\\n\",\n",
    "    \"            validation = \\\"Validation failed\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Save to memory\\n\",\n",
    "    \"    vsm = VectorStoreManager()\\n\",\n",
    "    \"    vsm.add_experience(task, snippet, result.get(\\\"refactored_code\\\", snippet), result.get(\\\"issues_found\\\", []), validation)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    with open(\\\"output.json\\\", \\\"w\\\") as f:\\n\",\n",
    "    \"        json.dump(result, f, indent=2)\\n\",\n",
    "    \"    return result\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"# MAIN: ASK QUESTION (RetrievalQA)\\n\",\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"def ask_question(query, file_path):\\n\",\n",
    "    \"    code = Path(file_path).read_text(encoding='utf-8')\\n\",\n",
    "    \"    vsm = VectorStoreManager()\\n\",\n",
    "    \"    vsm.add_experience(\\\"stored\\\", code, code, [], \\\"Original code\\\")\\n\",\n",
    "    \"    context = vsm.retrieve(query)\\n\",\n",
    "    \"    qa = create_qa_chain()\\n\",\n",
    "    \"    answer = qa.invoke({\\\"context\\\": context, \\\"question\\\": query})\\n\",\n",
    "    \"    print(f\\\"❓ {query}\\\\n💡 {answer}\\\")\\n\",\n",
    "    \"    return answer\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"# RUN: DEBUG\\n\",\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"result = code_assistant(\\\"sample_code/buggy.py\\\", \\\"debug\\\")\\n\",\n",
    "    \"print(\\\"\\\\n🔍 DEBUG RESULT:\\\")\\n\",\n",
    "    \"print(json.dumps(result, indent=2))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"# RUN: RETRIEVALQA\\n\",\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"ask_question(\\\"What does find_max do and how can I fix it?\\\", \\\"sample_code/buggy.py\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 🎯 Submission Ready!\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook:\\n\",\n",
    "    \"- ✅ Implements **all 9 requirements**\\n\",\n",
    "    \"- ✅ Uses **active Groq model** (`llama-3.3-70b-versatile`)\\n\",\n",
    "    \"- ✅ Includes **workflow diagram**\\n\",\n",
    "    \"- ✅ Produces **structured JSON output**\\n\",\n",
    "    \"- ✅ Demonstrates **agent + RetrievalQA**\\n\",\n",
    "    \"\\n\",\n",
    "    \"**To submit**: Download this notebook (`File > Download`) and include your `.env` or replace the API key placeholder.\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.10.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
